{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## makemore: becoming a backprop ninja\n",
    "\n",
    "swole doge style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there no change change in the first several cells from last lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok biolerplate done, now we get to the action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3250, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "dprobs = (1.0 / probs) * dlogprobs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "dnorm_logits = counts * dcounts\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "dhpreact = (1.0 - h**2) * dh\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "dbndiff += (2*bndiff) * dbndiff2\n",
    "dhprebn = dbndiff.clone()\n",
    "dbnmeani = (-dbndiff).sum(0)\n",
    "dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "demb = dembcat.view(emb.shape)\n",
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "  for j in range(Xb.shape[1]):\n",
    "    ix = Xb[k,j]\n",
    "    dC[ix] += demb[k,j]\n",
    "    \n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.325015068054199 diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 9.080395102500916e-09\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(n), Yb] -= 1\n",
    "dlogits /= n\n",
    "\n",
    "cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0814, 0.0839, 0.0200, 0.0433, 0.0196, 0.0797, 0.0230, 0.0341, 0.0174,\n",
       "        0.0331, 0.0405, 0.0383, 0.0398, 0.0289, 0.0377, 0.0133, 0.0092, 0.0194,\n",
       "        0.0150, 0.0507, 0.0467, 0.0211, 0.0297, 0.0690, 0.0578, 0.0263, 0.0212],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0814,  0.0839,  0.0200,  0.0433,  0.0196,  0.0797,  0.0230,  0.0341,\n",
       "        -0.9826,  0.0331,  0.0405,  0.0383,  0.0398,  0.0289,  0.0377,  0.0133,\n",
       "         0.0092,  0.0194,  0.0150,  0.0507,  0.0467,  0.0211,  0.0297,  0.0690,\n",
       "         0.0578,  0.0263,  0.0212], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0] * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.6566e-10, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15bb546e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: backprop through batchnorm but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
    "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# before we had:\n",
    "# dbnraw = bngain * dhpreact\n",
    "# dbndiff = bnvar_inv * dbnraw\n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "# dbndiff += (2*bndiff) * dbndiff2\n",
    "# dhprebn = dbndiff.clone()\n",
    "# dbnmeani = (-dbndiff).sum(0)\n",
    "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "\n",
    "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
    "# (you'll also need to use some of the variables from the forward pass up above)\n",
    "\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhprebn.shape, bngain.shape, bnvar_inv.shape, dbnraw.shape, dbnraw.sum(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n",
      "      0/ 200000: 3.7851\n",
      "  10000/ 200000: 2.1849\n",
      "  20000/ 200000: 2.4208\n",
      "  30000/ 200000: 2.4703\n",
      "  40000/ 200000: 2.0346\n",
      "  50000/ 200000: 2.3846\n",
      "  60000/ 200000: 2.3803\n",
      "  70000/ 200000: 2.0757\n",
      "  80000/ 200000: 2.3556\n",
      "  90000/ 200000: 2.1370\n",
      " 100000/ 200000: 2.0215\n",
      " 110000/ 200000: 2.2908\n",
      " 120000/ 200000: 1.9773\n",
      " 130000/ 200000: 2.3526\n",
      " 140000/ 200000: 2.3776\n",
      " 150000/ 200000: 2.1460\n",
      " 160000/ 200000: 1.9274\n",
      " 170000/ 200000: 1.8064\n",
      " 180000/ 200000: 1.9750\n",
      " 190000/ 200000: 1.9674\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "  # kick off optimization\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # Linear layer\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    # BatchNorm layer\n",
    "    # -------------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -------------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "      p.grad = None\n",
    "    #loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop! #swole_doge_meme\n",
    "    # -----------------\n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    # tanh\n",
    "    dhpreact = (1.0 - h**2) * dh\n",
    "    # batchnorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    # 1st layer\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    # embedding\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    for k in range(Xb.shape[0]):\n",
    "      for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    # -----------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every once in a while\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "  #   if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "  #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful for checking your gradients\n",
    "# for p,g in zip(parameters, grads):\n",
    "#   cmp(str(tuple(p.shape)), g, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the batch norm at the end of training\n",
    "\n",
    "with torch.no_grad():\n",
    "  # pass the training set through\n",
    "  emb = C[Xtr]\n",
    "  embcat = emb.view(emb.shape[0], -1)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  # measure the mean/std over the entire training set\n",
    "  bnmean = hpreact.mean(0, keepdim=True)\n",
    "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.0708131790161133\n",
      "val 2.110647201538086\n"
     ]
    }
   ],
   "source": [
    "# evaluate train and val loss\n",
    "\n",
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  emb = C[x] # (N, block_size, n_embd)\n",
    "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "  logits = h @ W2 + b2 # (N, vocab_size)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I achieved:\n",
    "# train 2.0718822479248047\n",
    "# val 2.1162495613098145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carmah.\n",
      "amelle.\n",
      "khyimri.\n",
      "reetlanna.\n",
      "sane.\n",
      "mahnen.\n",
      "deliah.\n",
      "jareei.\n",
      "nellara.\n",
      "chaiivon.\n",
      "leigh.\n",
      "ham.\n",
      "join.\n",
      "quinn.\n",
      "shoilea.\n",
      "jadiquin.\n",
      "elogiearynix.\n",
      "kaellissa.\n",
      "med.\n",
      "edi.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # ------------\n",
    "      # forward pass:\n",
    "      # Embedding\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)      \n",
    "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "      hpreact = embcat @ W1 + b1\n",
    "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "      logits = h @ W2 + b2 # (N, vocab_size)\n",
    "      # ------------\n",
    "      # Sample\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
