{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bb02cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bac01bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  196113\n"
     ]
    }
   ],
   "source": [
    "# create the dataset\n",
    "xs, ys, zs = [], [], []\n",
    "for w in words:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  #print(chs)\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    #print(ch1, ch2, ch3)\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    ix3 = stoi[ch3]\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "    zs.append(ix3)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "zs = torch.tensor(zs)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# initialize the 'network'\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((54, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bfe6cb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.186270713806152\n",
      "3.357367992401123\n",
      "3.0421485900878906\n",
      "2.8714542388916016\n",
      "2.7671942710876465\n",
      "2.694681167602539\n",
      "2.639092206954956\n",
      "2.5949816703796387\n",
      "2.559002637863159\n",
      "2.529222011566162\n",
      "2.5042335987091064\n",
      "2.483072519302368\n",
      "2.464961051940918\n",
      "2.4493141174316406\n",
      "2.435654401779175\n",
      "2.423619031906128\n",
      "2.412919521331787\n",
      "2.4033381938934326\n",
      "2.394700527191162\n",
      "2.386871099472046\n",
      "2.379739999771118\n",
      "2.3732173442840576\n",
      "2.3672287464141846\n",
      "2.3617119789123535\n",
      "2.3566131591796875\n",
      "2.3518879413604736\n",
      "2.34749698638916\n",
      "2.343406915664673\n",
      "2.3395884037017822\n",
      "2.3360157012939453\n",
      "2.332667112350464\n",
      "2.3295228481292725\n",
      "2.3265650272369385\n",
      "2.3237788677215576\n",
      "2.3211495876312256\n",
      "2.3186655044555664\n",
      "2.3163154125213623\n",
      "2.314089059829712\n",
      "2.3119773864746094\n",
      "2.3099725246429443\n",
      "2.3080661296844482\n",
      "2.3062520027160645\n",
      "2.3045237064361572\n",
      "2.302875518798828\n",
      "2.301301956176758\n",
      "2.2997987270355225\n",
      "2.298360824584961\n",
      "2.2969841957092285\n",
      "2.2956652641296387\n",
      "2.294400691986084\n",
      "2.293186902999878\n",
      "2.2920210361480713\n",
      "2.290900468826294\n",
      "2.2898223400115967\n",
      "2.2887840270996094\n",
      "2.2877840995788574\n",
      "2.28682017326355\n",
      "2.2858901023864746\n",
      "2.2849924564361572\n",
      "2.284125328063965\n",
      "2.2832870483398438\n",
      "2.2824761867523193\n",
      "2.281691551208496\n",
      "2.2809317111968994\n",
      "2.280196189880371\n",
      "2.27948260307312\n",
      "2.2787907123565674\n",
      "2.2781195640563965\n",
      "2.27746844291687\n",
      "2.2768356800079346\n",
      "2.2762207984924316\n",
      "2.275623083114624\n",
      "2.2750420570373535\n",
      "2.2744767665863037\n",
      "2.2739264965057373\n",
      "2.273390769958496\n",
      "2.2728688716888428\n",
      "2.2723605632781982\n",
      "2.2718653678894043\n",
      "2.2713820934295654\n",
      "2.2709107398986816\n",
      "2.270451307296753\n",
      "2.2700023651123047\n",
      "2.269564390182495\n",
      "2.269136428833008\n",
      "2.268718719482422\n",
      "2.268310070037842\n",
      "2.267911195755005\n",
      "2.2675209045410156\n",
      "2.267139434814453\n",
      "2.26676607131958\n",
      "2.2664005756378174\n",
      "2.2660434246063232\n",
      "2.265693426132202\n",
      "2.265350818634033\n",
      "2.2650153636932373\n",
      "2.2646865844726562\n",
      "2.264364719390869\n",
      "2.2640492916107178\n",
      "2.263739824295044\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for k in range(100):\n",
    "  \n",
    "  # forward pass\n",
    "  xenc = F.one_hot(xs, num_classes=27).float() \n",
    "  yenc = F.one_hot(ys, num_classes=27).float() \n",
    "  totenc = torch.cat([xenc, yenc], 1) \n",
    "  logits = totenc @ W \n",
    "  counts = logits.exp() \n",
    "  probs = counts / counts.sum(1, keepdims=True) \n",
    "  loss = -probs[torch.arange(num), zs].log().mean() #+ 0.1*(W**2).mean()\n",
    "  print(loss.item())\n",
    "  \n",
    "  # backward pass\n",
    "  W.grad = None # set to zero the gradient\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cf85755f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae.\n",
      "za.\n",
      "ahallurailaziayh.\n",
      "avinish.\n",
      "na.\n"
     ]
    }
   ],
   "source": [
    "#sampling from the model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "\n",
    "for i in range(5):\n",
    "  out = []\n",
    "  context = [0, 0]\n",
    "  while True:\n",
    "    \n",
    "    # ----------\n",
    "    # BEFORE:\n",
    "    #p = P[ix]\n",
    "    # ----------\n",
    "    # NOW:\n",
    "    xenc = F.one_hot(torch.tensor([context[0]]), num_classes=27).float() \n",
    "    yenc = F.one_hot(torch.tensor([context[1]]), num_classes=27).float() \n",
    "    totenc = torch.cat([xenc, yenc], 1)\n",
    "    logits = totenc @ W # predict log-counts\n",
    "    counts = logits.exp()\n",
    "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    # ----------\n",
    "    \n",
    "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "\n",
    "    context[0] = context[1]\n",
    "    context[1] = ix\n",
    "    \n",
    "    if ix == 0:\n",
    "      break\n",
    "  print(''.join(out))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
